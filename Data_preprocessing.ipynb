{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17f722ae-e5cb-489d-b323-e1490aa19433",
   "metadata": {},
   "source": [
    "-------------------------My code-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c5f17b8-83ff-467a-aed4-6b5b5ae7971a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import emoji\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ed8044a-f6c7-4c6c-aa6f-dd2f2e0fb45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0    Emotion                                           Sentence\n",
      "0            188      Other              cho mình xin bài nhạc tên là gì với ạ\n",
      "1            166    Disgust  cho đáng đời con quỷ . về nhà lôi con nhà mày ...\n",
      "2           1345    Disgust  lo học đi . yêu đương lol gì hay lại thích học...\n",
      "3            316  Enjoyment    uớc gì sau này về già vẫn có thể như cụ này :))\n",
      "4           1225  Enjoyment  mỗi lần có video của con là cứ coi đi coi lại ...\n",
      "...          ...        ...                                                ...\n",
      "5543        1332    Disgust  đường của nhà cụ hay sao mà cụ cấm người ta đỗ...\n",
      "5544         825      Other                             nhìn mặt héo queo luôn\n",
      "5545         165      Other  tao đi xe máy mỗi lần muốn để xe đi đâu là phi...\n",
      "5546         363  Enjoyment                    thích thân hình boss rồi nhan 😌\n",
      "5547        1242    Sadness  ước mơ nhỏ nhoi của tao là được làm chị mà khô...\n",
      "\n",
      "[5548 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Đọc file Excel\n",
    "training_dataset_path = \"C:\\\\Users\\\\HS\\\\Desktop\\\\Project_AI\\\\NLP\\\\datasets_test\\\\train_nor_811.xlsx\"\n",
    "dataset = pd.read_excel(training_dataset_path)\n",
    "\n",
    "# Hiển thị dữ liệu\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f97aeb37-7f95-4980-820d-0171646b27d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xin lô ̃ i chư ́ tao te ́ ma ̀ thă ̀ người lz camera quay câ ̣ n mă ̣ tao như thê ́ thi ̀ tao đe ́ o đa ́ không đâu\n",
      "['xin', 'lô', '̃', 'i', 'chư', '́', 'tao', 'te', '́', 'ma', '̀', 'thă', '̀', 'người', 'lz', 'camera', 'quay', 'câ', '̣', 'n', 'mă', '̣', 'tao', 'như', 'thê', '́', 'thi', '̀', 'tao', 'đe', '́', 'o', 'đa', '́', 'không', 'đâu']\n"
     ]
    }
   ],
   "source": [
    "print(dataset.loc[84, 'Sentence'])\n",
    "print((dataset.loc[84, 'Sentence']).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfcd687f-8bb2-48b4-907c-c2e22ea0d2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "anger_data = dataset.loc[dataset[\"Emotion\"] == 'Anger']\n",
    "disgust_data = dataset.loc[dataset[\"Emotion\"] == 'Disgust']\n",
    "enjoyment_data = dataset.loc[dataset[\"Emotion\"] == 'Enjoyment']\n",
    "fear_data = dataset.loc[dataset[\"Emotion\"] == 'Fear']\n",
    "sadness_data = dataset.loc[dataset[\"Emotion\"] == 'Sadness']\n",
    "surprise_data = dataset.loc[dataset[\"Emotion\"] == 'Surprise']\n",
    "other_data = dataset.loc[dataset[\"Emotion\"] == 'Other']\n",
    "\n",
    "excel_file_path1 = 'C:\\\\Users\\\\HS\\\\Desktop\\\\Project_AI\\\\NLP\\\\datasets_test\\\\anger_icons.xlsx' \n",
    "anger_data.to_excel(excel_file_path1, index=False)\n",
    "\n",
    "excel_file_path2 = 'C:\\\\Users\\\\HS\\\\Desktop\\\\Project_AI\\\\NLP\\\\datasets_test\\\\disgust_icons.xlsx' \n",
    "disgust_data.to_excel(excel_file_path2, index=False)\n",
    "\n",
    "excel_file_path3 = 'C:\\\\Users\\\\HS\\\\Desktop\\\\Project_AI\\\\NLP\\\\datasets_test\\\\enjoyment_icons.xlsx' \n",
    "enjoyment_data.to_excel(excel_file_path3, index=False)\n",
    "\n",
    "excel_file_path4 = 'C:\\\\Users\\\\HS\\\\Desktop\\\\Project_AI\\\\NLP\\\\datasets_test\\\\fear_icons.xlsx' \n",
    "fear_data.to_excel(excel_file_path4, index=False)\n",
    "\n",
    "excel_file_path5 = 'C:\\\\Users\\\\HS\\\\Desktop\\\\Project_AI\\\\NLP\\\\datasets_test\\\\sadness_icons.xlsx' \n",
    "sadness_data.to_excel(excel_file_path5, index=False)\n",
    "\n",
    "excel_file_path6 = 'C:\\\\Users\\\\HS\\\\Desktop\\\\Project_AI\\\\NLP\\\\datasets_test\\\\surprise_icons.xlsx' \n",
    "surprise_data.to_excel(excel_file_path6, index=False)\n",
    "\n",
    "excel_file_path7 = 'C:\\\\Users\\\\HS\\\\Desktop\\\\Project_AI\\\\NLP\\\\datasets_test\\\\other_icons.xlsx' \n",
    "other_data.to_excel(excel_file_path7, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "797e81ab-72f3-4799-8686-9c8d28fdc0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0 Emotion                                           Sentence\n",
      "0          1220   Anger  thằng kia sao mày bắt vợ với bồ tao dọn thế ki...\n",
      "1          1249   Anger  ko phải con mình , mà xem còn thấy đau như vậy...\n",
      "2          1750   Anger  con chó đăng video , mày bị ngu à mà mỗi mẩu l...\n",
      "3          1272   Anger  cá nhân mình nghĩ nó dừng hay đỗ đúng sai thì ...\n",
      "4          1573   Anger                              đéo được tích sự gì 😂\n",
      "..          ...     ...                                                ...\n",
      "386         427   Anger  nói tới thì lại dỗi bỏ được mấy đồng ra rồi bà...\n",
      "387         519   Anger  dm tao thấy người ta không sợ vì rắn mà sợ vì ...\n",
      "388        1828   Anger  thế mà lại có người bảo đầu tao như đầu bùi :(...\n",
      "389         629   Anger  moẹ s tuổi thơ của tôi toàn găp phải thằng mất...\n",
      "390         626   Anger  sao không cho con già đấy mấy cái vào mõm cho ...\n",
      "\n",
      "[391 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(anger_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "87123a35-c3f9-4aa4-ad84-1da167e75f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0  Emotion                                           Sentence\n",
      "391          166  Disgust  cho đáng đời con quỷ . về nhà lôi con nhà mày ...\n",
      "392         1345  Disgust  lo học đi . yêu đương lol gì hay lại thích học...\n",
      "393         1785  Disgust        đòn tấn công cực gắt và cục sút của anh 😂😂😂\n",
      "394         1398  Disgust             mấy thằng củ lol việt nam nhảm nhí :))\n",
      "395          303  Disgust               coi video chưa hiểu gì đã làm ầm lên\n",
      "...          ...      ...                                                ...\n",
      "1457         158  Disgust             cấp 1 đi học cũng gặp bọn quái đản này\n",
      "1458        1869  Disgust                             cái thứ gì đâu không 😈\n",
      "1459        1282  Disgust   trời ơi càng ngày ổ càng giống con đuông dừa 😑😑😑\n",
      "1460         655  Disgust  cho nên đư ̀ người bao giờ cô ́ tỏ ra la ̀ ca ...\n",
      "1461        1332  Disgust  đường của nhà cụ hay sao mà cụ cấm người ta đỗ...\n",
      "\n",
      "[1071 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(disgust_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0eee6ae6-7fdb-4cb3-ab13-7c532ccca3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0    Emotion                                           Sentence\n",
      "1462         316  Enjoyment    uớc gì sau này về già vẫn có thể như cụ này :))\n",
      "1463        1225  Enjoyment  mỗi lần có video của con là cứ coi đi coi lại ...\n",
      "1464        1523  Enjoyment                        công nhận sáng tạo thật đấy\n",
      "1465         776  Enjoyment                                   minh biết nữa ne\n",
      "1466         298  Enjoyment  sau em này mà làm cô giáo ngồi kể chuyện hs lạ...\n",
      "...          ...        ...                                                ...\n",
      "3015         724  Enjoyment                 đồng nghiệp của tôi thật tuyệt vời\n",
      "3016          95  Enjoyment  nhìn đôi bàn tay đã biết phải lao động rồi . c...\n",
      "3017        1033  Enjoyment               cứ thấy trai đẹp là tao hạnh phúc :)\n",
      "3018        1278  Enjoyment  tao là trùm nấu cơm kiểu này rồi ,, còn bây gi...\n",
      "3019         363  Enjoyment                    thích thân hình boss rồi nhan 😌\n",
      "\n",
      "[1558 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(enjoyment_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "354273ac-7293-4113-a1c3-1826c23c5e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0 Emotion                                           Sentence\n",
      "3020         191    Fear  thời buổi bây chừ chuyện gì cũng có thể xảy ra...\n",
      "3021          29    Fear  từ đầu năm giờ chắc chụp 10 lần rồi huhu sợ qu...\n",
      "3022         337    Fear                 t gặp quả này thì bỏ xe mà chạy ??\n",
      "3023         205    Fear          muốn share về mà sợ bị bạn nè phẫn nộ quá\n",
      "3024         298    Fear  cv không áp lực , môi trường xung quanh mới dễ...\n",
      "...          ...     ...                                                ...\n",
      "3333         395    Fear  hôm trước tao đi chơi về đường vắng nên chạy n...\n",
      "3334          97    Fear                         t chỉ sợ cảnh đấu kiếm :((\n",
      "3335         272    Fear                              per =)))) đáng sợ vãi\n",
      "3336         345    Fear  per đi bộ ở trường về thì dcm nổi ám ảnh đúng ...\n",
      "3337         131    Fear  ánh mắt thằng con muốn nói : cứu cháu hình như...\n",
      "\n",
      "[318 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(fear_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "fc98c5cb-9423-4bda-a577-d180b1bc4dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0  Emotion                                           Sentence\n",
      "4359        1063  Sadness  per nghe đi rồi khóc 1 trận cho thoải mái . đừ...\n",
      "4360         497  Sadness  tui thi ́ ch va ̉ i lă ́ mày ma ̀ ăn nhỉ ̀ u n...\n",
      "4361        1503  Sadness  mày định lướt qua rồi nhưng khi đọc bình luận ...\n",
      "4362         419  Sadness  xin đi chơi với bạn ngày tổng kết không cho cứ...\n",
      "4363        1080  Sadness  hồi học lớp 5 bảo bố đi mua sgk cho , xong bố ...\n",
      "...          ...      ...                                                ...\n",
      "5301         534  Sadness  sau 15 năm cắp sách đi học và 2 , 5 năm không ...\n",
      "5302        1234  Sadness  hôm qua tao xem xong ngất xỉu tới giờ mới tĩnh...\n",
      "5303         507  Sadness      sau cùng cả 2 đều bị ảnh hưởng trầm trọng :((\n",
      "5304         754  Sadness                 và tôi đã mất đi 1 người như thế .\n",
      "5305        1242  Sadness  ước mơ nhỏ nhoi của tao là được làm chị mà khô...\n",
      "\n",
      "[947 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(sadness_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b25ddcd9-f944-4944-a543-8e74ac23bbce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0   Emotion                                           Sentence\n",
      "5306        1951  Surprise           thật hay đùa ác vậy . không thể tin được\n",
      "5307        1782  Surprise  per đây mí chính là cụ tổ của những chiếc sừng...\n",
      "5308        1733  Surprise                     canh thời gian đăng đúng vãi !\n",
      "5309        1714  Surprise  xem cái này mới biết vốn tiếng anh của mình cũ...\n",
      "5310        1946  Surprise      không hiểu sao nhìu người lại thả haha nhỉ ??\n",
      "...          ...       ...                                                ...\n",
      "5543        1757  Surprise                 ae họ mà đéo biết mặt nhau à - _ -\n",
      "5544        1864  Surprise                                           rất giỏi\n",
      "5545        1655  Surprise                      giống găng tay của thanos vậy\n",
      "5546        1933  Surprise                          vẻ đẹp phi giới tính luôn\n",
      "5547        1895  Surprise                           sao giá ảo quá vậy :))))\n",
      "\n",
      "[242 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(surprise_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "17e25856-882d-48da-83ad-7284a0bec2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0 Emotion                                           Sentence\n",
      "3338         188   Other              cho mình xin bài nhạc tên là gì với ạ\n",
      "3339          44   Other                      một lí do trog muôn vàn lí do\n",
      "3340        1069   Other  trời nắng nóng thế này mình muốn bán nước khôn...\n",
      "3341         562   Other                       bếp dầu , nhiều nhà vẫn dùng\n",
      "3342         327   Other  nếu thấy phụ nữ quá phức tạp để hiểu và chinh ...\n",
      "...          ...     ...                                                ...\n",
      "4354         888   Other         per nét chữ giống hệt chữ của tao luôn mày\n",
      "4355        1034   Other                         per chắc là mày đi hốt này\n",
      "4356         969   Other                          cảm giác lúc ấy sẽ ra sao\n",
      "4357         825   Other                             nhìn mặt héo queo luôn\n",
      "4358         165   Other  tao đi xe máy mỗi lần muốn để xe đi đâu là phi...\n",
      "\n",
      "[1021 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(other_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4741a645-6372-459b-8d22-00fb3b2b96fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "VN_CHARS_LOWER = u'ạảãàáâậầấẩẫăắằặẳẵóòọõỏôộổỗồốơờớợởỡéèẻẹẽêếềệểễúùụủũưựữửừứíìịỉĩýỳỷỵỹđð'\n",
    "VN_CHARS_UPPER = u'ẠẢÃÀÁÂẬẦẤẨẪĂẮẰẶẲẴÓÒỌÕỎÔỘỔỖỒỐƠỜỚỢỞỠÉÈẺẸẼÊẾỀỆỂỄÚÙỤỦŨƯỰỮỬỪỨÍÌỊỈĨÝỲỶỴỸÐĐ'\n",
    "VN_CHARS = VN_CHARS_LOWER + VN_CHARS_UPPER\n",
    "\n",
    "#loại bỏ các dấu trong trong câu\n",
    "def no_marks(text):\n",
    "    __INTAB = [ch for ch in VN_CHARS]\n",
    "    __OUTTAB = \"a\"*17 + \"o\"*17 + \"e\"*11 + \"u\"*11 + \"i\"*5 + \"y\"*5 + \"d\"*2\n",
    "    __OUTTAB += \"A\"*17 + \"O\"*17 + \"E\"*11 + \"U\"*11 + \"I\"*5 + \"Y\"*5 + \"D\"*2\n",
    "    __r = re.compile(\"|\".join(__INTAB))\n",
    "    __replaces_dict = dict(zip(__INTAB, __OUTTAB))\n",
    "    result = __r.sub(lambda m: __replaces_dict[m.group(0)], text)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "61deb27a-9d67-45a3-b839-ac0902704033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    #Chuẩn hóa tiếng Việt, xử lý emoj, chuẩn hóa tiếng Anh, thuật ngữ\n",
    "    replace_list = {\n",
    "        'òa': 'oà', 'óa': 'oá', 'ỏa': 'oả', 'õa': 'oã', 'ọa': 'oạ', 'òe': 'oè', 'óe': 'oé','ỏe': 'oẻ',\n",
    "        'õe': 'oẽ', 'ọe': 'oẹ', 'ùy': 'uỳ', 'úy': 'uý', 'ủy': 'uỷ', 'ũy': 'uỹ','ụy': 'uỵ', 'uả': 'ủa',\n",
    "        'ả': 'ả', 'ố': 'ố', 'u´': 'ố','ỗ': 'ỗ', 'ồ': 'ồ', 'ổ': 'ổ', 'ấ': 'ấ', 'ẫ': 'ẫ', 'ẩ': 'ẩ',\n",
    "        'ầ': 'ầ', 'ỏ': 'ỏ', 'ề': 'ề','ễ': 'ễ', 'ắ': 'ắ', 'ủ': 'ủ', 'ế': 'ế', 'ở': 'ở', 'ỉ': 'ỉ',\n",
    "        'ẻ': 'ẻ', 'àk': u' à ','aˋ': 'à', 'iˋ': 'ì', 'ă´': 'ắ','ử': 'ử', 'e˜': 'ẽ', 'y˜': 'ỹ', 'a´': 'á',\n",
    "        #Chuẩn hóa 1 số sentiment words/English words\n",
    "        'okie': 'ok', 'oki': 'ok', 'okey': 'ok', 'ôkê': 'ok', 'oki': 'ok', 'oke': 'ok', 'okay': 'ok', 'okê': 'ok', u'o kê': 'ok', u'o kêi': 'ok',\n",
    "        'tks': u'cám ơn', 'thks': u'cám ơn', 'thanks': u'cám ơn', 'ths': u'cám ơn', 'thank': u'cám ơn', u'then kiu': u'cám ơn', u'thanh kù': u'cám ơn',\n",
    "        'not ': u'không ', u'kg ': u'không ', u'k ': 'không ', 'kh ':u'không ', 'kô ': u'không ', 'hok ': u'không ', 'kp ': u'không phải ','kô ': u'không ', 'ko ': u'không ', 'khong': 'không ',\n",
    "        u'he he': ' positive ', u'ha ha': ' positive ', u'hi hi': ' positive ','hehe': ' positive ', 'hihi': ' positive ', 'haha': ' positive ', 'hjhj': ' positive ',\n",
    "        ' lol ': ' nagative ','cc': ' nagative ','cute': u' dễ thương ','huhu': ' nagative ', ' vs ': u' với ', 'wa': ' quá ', 'wá': u' quá', 'j': u' gì ', '“': ' ',\n",
    "        ' sz ': u' cỡ ', 'size': u' cỡ ', u' đx ': u' được ', 'dk': u' được ', 'dc': u' được ', 'đk': u' được ',\n",
    "        'đc': u' được ','authentic': u' chuẩn chính hãng ',u' aut ': u' chuẩn chính hãng ', u' auth ': u' chuẩn chính hãng ', 'thick': u' positive ', 'store': u' cửa hàng ',\n",
    "        'shop': u' cửa hàng ', 'sp': u' sản phẩm ', 'gud': u' tốt ','god': u' tốt ','wel done':' tốt ', 'good': u' tốt ', 'gút': u' tốt ',\n",
    "        'sấu': u' xấu ','gut': u' tốt ', u' tot ': u' tốt ', u' nice ': u' tốt ', 'perfect': 'rất tốt', 'bt': u' bình thường ',\n",
    "        'time': u' thời gian ', 'qá': u' quá ', u' ship ': u' giao hàng ', u' m ': u' mình ', u' mik ': u' mình ',\n",
    "        'ể': 'ể', 'product': 'sản phẩm', 'quality': 'chất lượng','chat':' chất ', 'excelent': 'hoàn hảo', 'bad': 'tệ','fresh': ' tươi ','sad': ' tệ ',\n",
    "        'date': u' hạn sử dụng ', 'hsd': u' hạn sử dụng ','quickly': u' nhanh ', 'quick': u' nhanh ','fast': u' nhanh ','delivery': u' giao hàng ',u' síp ': u' giao hàng ',\n",
    "        'beautiful': u' đẹp tuyệt vời ', u' tl ': u' trả lời ', u' r ': u' rồi ', u' shopE ': u' cửa hàng ',u' order ': u' đặt hàng ',\n",
    "        'chất lg': u' chất lượng ',u' sd ': u' sử dụng ',u' dt ': u' điện thoại ',u' nt ': u' nhắn tin ',u' tl ': u' trả lời ',u' sài ': u' xài ',u'bjo':u' bao giờ ',\n",
    "        'thik': u' thích ',u' sop ': u' cửa hàng ', ' fb ': ' facebook ', ' face ': ' facebook ', ' very ': u' rất ',u'quả ng ':u' quảng  ',\n",
    "        'dep': u' đẹp ',u' xau ': u' xấu ','delicious': u' ngon ', u'hàg': u' hàng ', u'qủa': u' quả ',\n",
    "        'iu': u' yêu ','fake': u' giả mạo ', 'trl': 'trả lời',\n",
    "        ' por ': u' tệ ',' poor ': u' tệ ', 'ib':u' nhắn tin ', 'rep':u' trả lời ',u'fback':' feedback ','fedback':' feedback '}\n",
    "\n",
    "    for k, v in replace_list.items():\n",
    "        text = text.replace(k, v)\n",
    "\n",
    "    #remove nốt những ký tự thừa thãi\n",
    "    text = text.replace(u'\"', u'')\n",
    "    text = text.replace(u'️', u'')\n",
    "    text = text.replace('🏻','')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f9f072e-7c58-4de2-8661-181deeb8bcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "icon = {\n",
    "    '😡': 'anger','😠': 'anger','😤': 'anger','💢': 'anger','🤬': 'anger','👿': 'anger','💣': 'anger','🔥': 'anger','💥': 'anger','🌋': 'anger',\n",
    "    #-----------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    '🤢': 'disgust','😖': 'disgust','😣': 'disgust','😷': 'disgust','🤮': 'disgust','🤕': 'disgust','🤒': 'disgust','🤧': 'disgust',\n",
    "    '💩': 'disgust','💔': 'disgust',\n",
    "    #-----------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    '😄': 'enjoyment','😃': 'enjoyment','😀': 'enjoyment','😁': 'enjoyment','😆': 'enjoyment','😅': 'enjoyment','😂': 'enjoyment',\n",
    "    '🤣': 'enjoyment','😊': 'enjoyment','😇': 'enjoyment','😍': 'enjoyment','🥰': 'enjoyment','😎': 'enjoyment','🤩': 'enjoyment',\n",
    "    '😋': 'enjoyment','🥳': 'enjoyment',\n",
    "    #-----------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    '😨': 'Fear','😱': 'Fear','😰': 'Fear','😟': 'Fear','😦': 'Fear','😧': 'Fear','😮': 'Fear','😯': 'Fear','💀': 'Fear','👻': 'Fear',\n",
    "    '👹': 'Fear','👽': 'Fear',\n",
    "    #-----------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    '😢': 'sadness','😭': 'sadness','😞': 'sadness','😔': 'sadness','😟': 'sadness','😕': 'sadness','🙁': 'sadness','☹️': 'sadness',\n",
    "    '😖': 'sadness','😣': 'sadness','😓': 'sadness','😩': 'sadness','😫': 'sadness','😰': 'sadness','😥': 'sadness',\n",
    "    #-----------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    '😲': 'surprise','😯': 'surprise','😦': 'surprise','😧': 'surprise','😮': 'surprise','😱': 'surprise','😵': 'surprise',\n",
    "    '😳': 'surprise','🤯': 'surprise','🤩': 'surprise','😮‍💨': 'surprise'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "c5ae4b98-d6fa-4b1c-ad7b-5a21fa8e8352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove(text):\n",
    "    #Remove các ký tự kéo dài: vd: đẹppppppp\n",
    "    text = re.sub(r'([A-Z])\\1+', lambda m: m.group(1).upper(), text, flags=re.IGNORECASE)\n",
    "\n",
    "    #Chuyển \":))))))\" hoặc \":))))))))))))\" vè thành \":)\"\n",
    "    pattern = re.compile(r':\\)+')\n",
    "    text = pattern.sub(':)', text)\n",
    "\n",
    "    #Loại bỏ dấu \n",
    "    translation_table = str.maketrans(\"\", \"\", \"~!@#$%^&*(_+?/></*-;,.\")\n",
    "    text = text.translate(translation_table)\n",
    "    \n",
    "    #Chuyển thành chữ thường\n",
    "    text = text.lower()\n",
    "\n",
    "    #loại bỏ số trong câu\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "    #Loại bỏ khoảng trắng\n",
    "    #text = text.split()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "bc82490c-32b1-43d1-a59a-221a81871b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chỉ vì tin   nó không cắn đâu ” mà tao đã bị   nó ” cắn  lần rồi  dume\n",
      "['chỉ', 'vì', 'tin', 'nó', 'không', 'cắn', 'đâu', '”', 'mà', 'tao', 'đã', 'bị', 'nó', '”', 'cắn', 'lần', 'rồi', 'dume']\n",
      "xin lô ̃ i chư ́ tao te ́ ma ̀ thă ̀ người lz camera quay câ ̣ n mă ̣ tao như thê ́ thi ̀ tao đe ́ o đa ́ không đâu\n",
      "['xin', 'lô', '̃', 'i', 'chư', '́', 'tao', 'te', '́', 'ma', '̀', 'thă', '̀', 'người', 'lz', 'camera', 'quay', 'câ', '̣', 'n', 'mă', '̣', 'tao', 'như', 'thê', '́', 'thi', '̀', 'tao', 'đe', '́', 'o', 'đa', '́', 'không', 'đâu']\n"
     ]
    }
   ],
   "source": [
    "dataset.loc[84, 'Sentence'] = remove(dataset.loc[84, 'Sentence'])\n",
    "text = 'chỉ vì tin   nó không cắn đâu ” mà tao đã bị   nó ” cắn  lần rồi  dume'\n",
    "text = remove(text)\n",
    "print(text)\n",
    "print(text.split())\n",
    "print(dataset.loc[84, 'Sentence'])\n",
    "print((dataset.loc[84, 'Sentence']).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "64c1f1b2-66b8-48ff-868c-c830bd8d0e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loại bỏ stop words\n",
    "def remove_stopwords(sentence):\n",
    "    stopwords_VN = set([\"thì\",\"là\",\"mà\",\"và\",\"có\",\"được\",\"cho\",\"trong\",\"để\",\"với\",\"làm\",\"của\"])\n",
    "    words = sentence.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stopwords_VN]\n",
    "    return ' '.join(filtered_words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "fc808362-9a31-4da7-be5f-620b27ee4ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_icons(sentence):\n",
    "    # Chuyển đổi emoji trong chuỗi thành ký tự không dấu\n",
    "    without_emoji = emoji.demojize(sentence)\n",
    "\n",
    "    # Kiểm tra xem chuỗi có thay đổi sau khi loại bỏ emoji hay không\n",
    "    return without_emoji != sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "21305c1e-97d9-463b-816e-e7c052395bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chào thế giới đi :)😂 tôi công nhân đang đi chơi\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "input_str = \"Chào, thế.... giớ12121212iiiiiii Điiiiiiii!!!!!!!!! :))))))999999😂, tôi là công nhân và đang đi chơi'\"\n",
    "output_str = remove(input_str)\n",
    "output = check_icons(output_str)\n",
    "output_str = remove_stopwords(output_str)\n",
    "print(output_str)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "30d9e1a0-a6a9-4705-8a40-6a20f4ddc05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0 Emotion                                           Sentence\n",
      "0          1220   Anger  thằng kia sao mày bắt vợ với bồ tao dọn thế ki...\n",
      "1          1249   Anger  không phải con mình  mà xem còn thấy đau như v...\n",
      "2          1750   Anger  con chó đăng video  mày bị ngu à mà mỗi mẩu lạ...\n",
      "3          1272   Anger  cá nhân mình nghĩ nó dừng hay đỗ đúng sai thì ...\n",
      "4          1573   Anger                              đéo được tích sự gì 😂\n",
      "..          ...     ...                                                ...\n",
      "386         427   Anger  nói tới thì lại dỗi bỏ được mấy đồng ra rồi bà...\n",
      "387         519   Anger  dm tao thấy người ta không sợ vì rắn mà sợ vì ...\n",
      "388        1828   Anger  thế mà lại có người bảo đầu tao như đầu bùi : ...\n",
      "389         629   Anger  moẹ s tuổi thơ của tôi toàn găp phải thằng mất...\n",
      "390         626   Anger  sao không cho con già đấy mấy cái vào mõm cho ...\n",
      "\n",
      "[391 rows x 3 columns]\n",
      "      Unnamed: 0  Emotion                                           Sentence\n",
      "391          166  Disgust  cho đáng đời con quỷ  về nhà lôi con nhà mày r...\n",
      "392         1345  Disgust  lo học đi  yêu đương nagative gì hay lại thích...\n",
      "393         1785  Disgust        đòn tấn công cực gắt và cục sút của anh 😂😂😂\n",
      "394         1398  Disgust         mấy thằng củ nagative việt nam nhảm nhí :)\n",
      "395          303  Disgust               coi video chưa hiểu gì đã làm ầm lên\n",
      "...          ...      ...                                                ...\n",
      "1457         158  Disgust              cấp  đi học cũng gặp bọn quái đản này\n",
      "1458        1869  Disgust                             cái thứ gì đâu không 😈\n",
      "1459        1282  Disgust   trời ơi càng ngày ổ càng giống con đuông dừa 😑😑😑\n",
      "1460         655  Disgust  cho nên đư ̀ người bao giờ cô ́ tỏ ra la ̀ ca ...\n",
      "1461        1332  Disgust  đường của nhà cụ hay sao mà cụ cấm người ta đỗ...\n",
      "\n",
      "[1071 rows x 3 columns]\n",
      "      Unnamed: 0    Emotion                                           Sentence\n",
      "1462         316  Enjoyment     uớc gì sau này về già vẫn có thể như cụ này :)\n",
      "1463        1225  Enjoyment  mỗi lần có video của con là cứ coi đi coi lại ...\n",
      "1464        1523  Enjoyment                        công nhận sáng tạo thật đấy\n",
      "1465         776  Enjoyment                                   minh biết nữa ne\n",
      "1466         298  Enjoyment  sau em này mà làm cô giáo ngồi kể chuyện hs lạ...\n",
      "...          ...        ...                                                ...\n",
      "3015         724  Enjoyment                 đồng nghiệp của tôi thật tuyệt vời\n",
      "3016          95  Enjoyment  nhìn đôi bàn tay đã biết phải lao động rồi  ch...\n",
      "3017        1033  Enjoyment               cứ thấy trai đẹp là tao hạnh phúc :)\n",
      "3018        1278  Enjoyment  tao là trùm nấu cơm kiểu này rồi  còn bây giờ ...\n",
      "3019         363  Enjoyment                     thích thân hình bos rồi nhan 😌\n",
      "\n",
      "[1558 rows x 3 columns]\n",
      "      Unnamed: 0 Emotion                                           Sentence\n",
      "3020         191    Fear  thời buổi bây chừ chuyện gì cũng có thể xảy ra...\n",
      "3021          29    Fear  từ đầu năm giờ chắc chụp  lần rồi  nagative  s...\n",
      "3022         337    Fear                 t gặp  quả  này thì bỏ xe mà chạy \n",
      "3023         205    Fear          muốn share về mà sợ bị bạn nè phẫn nộ quá\n",
      "3024         298    Fear  cv không áp lực  môi trường xung quanh mới dễ ...\n",
      "...          ...     ...                                                ...\n",
      "3333         395    Fear  hôm trước tao đi chơi về đường vắng nên chạy n...\n",
      "3334          97    Fear                           t chỉ sợ cảnh đấu kiếm :\n",
      "3335         272    Fear                              per =)))) đáng sợ vãi\n",
      "3336         345    Fear  per đi bộ ở trường về thì  được mình nổi ám ản...\n",
      "3337         131    Fear  ánh mắt thằng con muốn nói : cứu cháu hình như...\n",
      "\n",
      "[318 rows x 3 columns]\n",
      "      Unnamed: 0  Emotion                                           Sentence\n",
      "4359        1063  Sadness  per nghe đi rồi khóc  trận cho thoải mái  đừng...\n",
      "4360         497  Sadness  tui thi ́ ch va ̉ i lă ́ mày ma ̀ ăn nhỉ ̀ u n...\n",
      "4361        1503  Sadness  mày định lướt qua rồi nhưng khi đọc bình luận ...\n",
      "4362         419  Sadness  xin đi chơi với bạn ngày tổng kết không cho cứ...\n",
      "4363        1080  Sadness  hồi học lớp  bảo bố đi mua sgkhông cho  xong b...\n",
      "...          ...      ...                                                ...\n",
      "5301         534  Sadness  sau  năm cắp sách đi học và    năm không động ...\n",
      "5302        1234  Sadness  hôm qua tao xem xong ngất xỉu tới giờ mới tĩnh...\n",
      "5303         507  Sadness         sau cùng cả  đều bị ảnh hưởng trầm trọng :\n",
      "5304         754  Sadness                   và tôi đã mất đi  người như thế \n",
      "5305        1242  Sadness  ước mơ nhỏ nhoi của tao là được làm chị mà khô...\n",
      "\n",
      "[947 rows x 3 columns]\n",
      "      Unnamed: 0   Emotion                                           Sentence\n",
      "5306        1951  Surprise            thật hay đùa ác vậy  không thể tin được\n",
      "5307        1782  Surprise  per đây mí chính là cụ tổ của những chiếc sừng...\n",
      "5308        1733  Surprise                      canh thời gian đăng đúng vãi \n",
      "5309        1714  Surprise  xem cái này mới biết vốn tiếng anh của mình cũ...\n",
      "5310        1946  Surprise  không hiểu sao nhìu người lại thả  positive  nhỉ \n",
      "...          ...       ...                                                ...\n",
      "5543        1757  Surprise                    ae họ mà đéo biết mặt nhau à   \n",
      "5544        1864  Surprise                                           rất giỏi\n",
      "5545        1655  Surprise                      giống găng tay của thanos vậy\n",
      "5546        1933  Surprise                          vẻ đẹp phi giới tính luôn\n",
      "5547        1895  Surprise                              sao giá ảo quá vậy :)\n",
      "\n",
      "[242 rows x 3 columns]\n",
      "      Unnamed: 0 Emotion                                           Sentence\n",
      "3338         188   Other              cho mình xin bài nhạc tên là gì với ạ\n",
      "3339          44   Other                      một lí do trog muôn vàn lí do\n",
      "3340        1069   Other  trời nắng nóng thế này mình muốn bán nước khôn...\n",
      "3341         562   Other                        bếp dầu  nhiều nhà vẫn dùng\n",
      "3342         327   Other  nếu thấy phụ nữ quá phức tạp để hiểu và chinh ...\n",
      "...          ...     ...                                                ...\n",
      "4354         888   Other         per nét chữ giống hệt chữ của tao luôn mày\n",
      "4355        1034   Other                         per chắc là mày đi hốt này\n",
      "4356         969   Other                          cảm giác lúc ấy sẽ ra sao\n",
      "4357         825   Other                             nhìn mặt héo queo luôn\n",
      "4358         165   Other  tao đi xe máy mỗi lần muốn để xe đi đâu là phi...\n",
      "\n",
      "[1021 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "anger_data_test = anger_data.copy()\n",
    "\n",
    "for row_index in range(0,391):\n",
    "    text = remove(anger_data_test.loc[row_index, 'Sentence'])\n",
    "    #text = remove_stopwords(text)\n",
    "    text = normalize_text(text)\n",
    "    anger_data_test.loc[row_index, 'Sentence'] = text\n",
    "print(anger_data_test)\n",
    "#----------------------------------------------------------------------------------------------\n",
    "disgust_data_test = disgust_data.copy()\n",
    "\n",
    "for row_index in range(391,1462):\n",
    "    text = remove(disgust_data_test.loc[row_index, 'Sentence'])\n",
    "    #text = remove_stopwords(text)\n",
    "    text = normalize_text(text)\n",
    "    disgust_data_test.loc[row_index, 'Sentence'] = text\n",
    "print(disgust_data_test)\n",
    "#----------------------------------------------------------------------------------------------\n",
    "enjoyment_data_test = enjoyment_data.copy()\n",
    "\n",
    "for row_index in range(1462,3020):\n",
    "    text = remove(enjoyment_data_test.loc[row_index, 'Sentence'])\n",
    "    #text = remove_stopwords(text)\n",
    "    text = normalize_text(text)\n",
    "    enjoyment_data_test.loc[row_index, 'Sentence'] = text\n",
    "print(enjoyment_data_test)\n",
    "#----------------------------------------------------------------------------------------------\n",
    "fear_data_test = fear_data.copy()\n",
    "\n",
    "for row_index in range(3020,3338):\n",
    "    text = remove(fear_data_test.loc[row_index, 'Sentence'])\n",
    "    #text = remove_stopwords(text)\n",
    "    text = normalize_text(text)\n",
    "    fear_data_test.loc[row_index, 'Sentence'] = text\n",
    "print(fear_data_test)\n",
    "#----------------------------------------------------------------------------------------------\n",
    "sadness_data_test = sadness_data.copy()\n",
    "\n",
    "for row_index in range(4359,5306):\n",
    "    text = remove(sadness_data_test.loc[row_index, 'Sentence'])\n",
    "    #text = remove_stopwords(text)\n",
    "    text = normalize_text(text)\n",
    "    sadness_data_test.loc[row_index, 'Sentence'] = text\n",
    "print(sadness_data_test)\n",
    "#----------------------------------------------------------------------------------------------\n",
    "surprise_data_test = surprise_data.copy()\n",
    "\n",
    "for row_index in range(5306,5548):\n",
    "    text = remove(surprise_data_test.loc[row_index, 'Sentence'])\n",
    "    #text = remove_stopwords(text)\n",
    "    text = normalize_text(text)\n",
    "    surprise_data_test.loc[row_index, 'Sentence'] = text\n",
    "print(surprise_data_test)\n",
    "#----------------------------------------------------------------------------------------------\n",
    "other_data_test = other_data.copy()\n",
    "\n",
    "for row_index in range(3338,4359):\n",
    "    text = remove(other_data_test.loc[row_index, 'Sentence'])\n",
    "    #text = remove_stopwords(text)\n",
    "    text = normalize_text(text)\n",
    "    other_data_test.loc[row_index, 'Sentence'] = text\n",
    "print(other_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "a53794dd-77b0-4bd1-89ee-a1de5c93ebcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "anger_data_test_icons = pd.DataFrame(columns=['id', 'Emotion', 'Sentence'])\n",
    "anger_data_test_non_icons = pd.DataFrame(columns=['id', 'Emotion', 'Sentence'])\n",
    "\n",
    "icons_index = 0\n",
    "non_icons_index = 0\n",
    "\n",
    "for row_index in range(0,391):\n",
    "    if check_icons(anger_data_test['Sentence'][row_index]) == False:\n",
    "        anger_data_test_non_icons.loc[non_icons_index] = anger_data_test.loc[row_index].values\n",
    "        non_icons_index += 1\n",
    "    else:\n",
    "        anger_data_test_icons.loc[icons_index] = anger_data_test.loc[row_index].values\n",
    "        icons_index += 1\n",
    "#-------------------------------------------------------------------------------------------------------\n",
    "disgust_data_test_icons = pd.DataFrame(columns=['id', 'Emotion', 'Sentence'])\n",
    "disgust_data_test_non_icons = pd.DataFrame(columns=['id', 'Emotion', 'Sentence'])\n",
    "\n",
    "icons_index = 0\n",
    "non_icons_index = 0\n",
    "\n",
    "for row_index in range(391,1462):\n",
    "    if check_icons(disgust_data_test['Sentence'][row_index]) == False:\n",
    "        disgust_data_test_non_icons.loc[non_icons_index] = disgust_data_test.loc[row_index].values\n",
    "        non_icons_index += 1\n",
    "    else:\n",
    "        disgust_data_test_icons.loc[icons_index] = disgust_data_test.loc[row_index].values\n",
    "        icons_index += 1\n",
    "#-------------------------------------------------------------------------------------------------------\n",
    "enjoyment_data_test_icons = pd.DataFrame(columns=['id', 'Emotion', 'Sentence'])\n",
    "enjoyment_data_test_non_icons = pd.DataFrame(columns=['id', 'Emotion', 'Sentence'])\n",
    "\n",
    "icons_index = 0\n",
    "non_icons_index = 0\n",
    "\n",
    "for row_index in range(1462,3020):\n",
    "    if check_icons(enjoyment_data_test['Sentence'][row_index]) == False:\n",
    "        enjoyment_data_test_non_icons.loc[non_icons_index] = enjoyment_data_test.loc[row_index].values\n",
    "        non_icons_index += 1\n",
    "    else:\n",
    "        enjoyment_data_test_icons.loc[icons_index] = enjoyment_data_test.loc[row_index].values\n",
    "        icons_index += 1\n",
    "#-------------------------------------------------------------------------------------------------------\n",
    "fear_data_test_icons = pd.DataFrame(columns=['id', 'Emotion', 'Sentence'])\n",
    "fear_data_test_non_icons = pd.DataFrame(columns=['id', 'Emotion', 'Sentence'])\n",
    "\n",
    "icons_index = 0\n",
    "non_icons_index = 0\n",
    "\n",
    "for row_index in range(3020,3338):\n",
    "    if check_icons(fear_data_test['Sentence'][row_index]) == False:\n",
    "        fear_data_test_non_icons.loc[non_icons_index] = fear_data_test.loc[row_index].values\n",
    "        non_icons_index += 1\n",
    "    else:\n",
    "        fear_data_test_icons.loc[icons_index] = fear_data_test.loc[row_index].values\n",
    "        icons_index += 1\n",
    "#-------------------------------------------------------------------------------------------------------\n",
    "sadness_data_test_icons = pd.DataFrame(columns=['id', 'Emotion', 'Sentence'])\n",
    "sadness_data_test_non_icons = pd.DataFrame(columns=['id', 'Emotion', 'Sentence'])\n",
    "\n",
    "icons_index = 0\n",
    "non_icons_index = 0\n",
    "\n",
    "for row_index in range(4359,5306):\n",
    "    if check_icons(sadness_data_test['Sentence'][row_index]) == False:\n",
    "        sadness_data_test_non_icons.loc[non_icons_index] = sadness_data_test.loc[row_index].values\n",
    "        non_icons_index += 1\n",
    "    else:\n",
    "        sadness_data_test_icons.loc[icons_index] = sadness_data_test.loc[row_index].values\n",
    "        icons_index += 1\n",
    "#-------------------------------------------------------------------------------------------------------\n",
    "surprise_data_test_icons = pd.DataFrame(columns=['id', 'Emotion', 'Sentence'])\n",
    "surprise_data_test_non_icons = pd.DataFrame(columns=['id', 'Emotion', 'Sentence'])\n",
    "\n",
    "icons_index = 0\n",
    "non_icons_index = 0\n",
    "\n",
    "for row_index in range(5306,5548):\n",
    "    if check_icons(surprise_data_test['Sentence'][row_index]) == False:\n",
    "        surprise_data_test_non_icons.loc[non_icons_index] = surprise_data_test.loc[row_index].values\n",
    "        non_icons_index += 1\n",
    "    else:\n",
    "        surprise_data_test_icons.loc[icons_index] = surprise_data_test.loc[row_index].values\n",
    "        icons_index += 1\n",
    "#-------------------------------------------------------------------------------------------------------\n",
    "other_data_test_icons = pd.DataFrame(columns=['id', 'Emotion', 'Sentence'])\n",
    "other_data_test_non_icons = pd.DataFrame(columns=['id', 'Emotion', 'Sentence'])\n",
    "\n",
    "icons_index = 0\n",
    "non_icons_index = 0\n",
    "\n",
    "for row_index in range(3338,4359):\n",
    "    if check_icons(other_data_test['Sentence'][row_index]) == False:\n",
    "        other_data_test_non_icons.loc[non_icons_index] = other_data_test.loc[row_index].values\n",
    "        non_icons_index += 1\n",
    "    else:\n",
    "        other_data_test_icons.loc[icons_index] = other_data_test.loc[row_index].values\n",
    "        icons_index += 1\n",
    "\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "f482822b-8bb6-4f9a-8862-93cf1dad2205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "excel_file_path1 = 'C:\\\\Users\\\\HS\\\\Desktop\\\\Project_AI\\\\NLP\\\\datasets\\\\anger_icons.xlsx' \n",
    "excel_file_path2 = 'C:\\\\Users\\\\HS\\\\Desktop\\\\Project_AI\\\\NLP\\\\datasets\\\\anger_non_icons.xlsx'\n",
    "anger_data_test_icons.to_excel(excel_file_path1, index=False)\n",
    "anger_data_test_non_icons.to_excel(excel_file_path2, index=False)\n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "excel_file_path1 = 'C:\\\\Users\\\\HS\\\\Desktop\\\\Project_AI\\\\NLP\\\\datasets\\\\disgust_icons.xlsx' \n",
    "excel_file_path2 = 'C:\\\\Users\\\\HS\\\\Desktop\\\\Project_AI\\\\NLP\\\\datasets\\\\disgust_non_icons.xlsx'\n",
    "disgust_data_test_icons.to_excel(excel_file_path1, index=False)\n",
    "disgust_data_test_non_icons.to_excel(excel_file_path2, index=False)\n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "excel_file_path1 = 'C:\\\\Users\\\\HS\\\\Desktop\\\\Project_AI\\\\NLP\\\\datasets\\\\enjoyment_icons.xlsx' \n",
    "excel_file_path2 = 'C:\\\\Users\\\\HS\\\\Desktop\\\\Project_AI\\\\NLP\\\\datasets\\\\enjoyment_non_icons.xlsx'\n",
    "enjoyment_data_test_icons.to_excel(excel_file_path1, index=False)\n",
    "enjoyment_data_test_non_icons.to_excel(excel_file_path2, index=False)\n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "excel_file_path1 = 'C:\\\\Users\\\\HS\\\\Desktop\\\\Project_AI\\\\NLP\\\\datasets\\\\fear_icons.xlsx' \n",
    "excel_file_path2 = 'C:\\\\Users\\\\HS\\\\Desktop\\\\Project_AI\\\\NLP\\\\datasets\\\\fear_non_icons.xlsx'\n",
    "fear_data_test_icons.to_excel(excel_file_path1, index=False)\n",
    "fear_data_test_non_icons.to_excel(excel_file_path2, index=False)\n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "excel_file_path1 = 'C:\\\\Users\\\\HS\\\\Desktop\\\\Project_AI\\\\NLP\\\\datasets\\\\sadness_icons.xlsx' \n",
    "excel_file_path2 = 'C:\\\\Users\\\\HS\\\\Desktop\\\\Project_AI\\\\NLP\\\\datasets\\\\sadness_non_icons.xlsx'\n",
    "sadness_data_test_icons.to_excel(excel_file_path1, index=False)\n",
    "sadness_data_test_non_icons.to_excel(excel_file_path2, index=False)\n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "excel_file_path1 = 'C:\\\\Users\\\\HS\\\\Desktop\\\\Project_AI\\\\NLP\\\\datasets\\\\surprise_icons.xlsx' \n",
    "excel_file_path2 = 'C:\\\\Users\\\\HS\\\\Desktop\\\\Project_AI\\\\NLP\\\\datasets\\\\surprise_non_icons.xlsx'\n",
    "surprise_data_test_icons.to_excel(excel_file_path1, index=False)\n",
    "surprise_data_test_non_icons.to_excel(excel_file_path2, index=False)\n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "excel_file_path1 = 'C:\\\\Users\\\\HS\\\\Desktop\\\\Project_AI\\\\NLP\\\\datasets\\\\other_icons.xlsx' \n",
    "excel_file_path2 = 'C:\\\\Users\\\\HS\\\\Desktop\\\\Project_AI\\\\NLP\\\\datasets\\\\other_non_icons.xlsx'\n",
    "other_data_test_icons.to_excel(excel_file_path1, index=False)\n",
    "other_data_test_non_icons.to_excel(excel_file_path2, index=False)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad432f5c-abff-4326-a1e3-ff8f3e479ee8",
   "metadata": {},
   "source": [
    "--------------------------Test-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "55f010be-920e-4c2e-895d-91e0a5af6500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ko phải con mình , mà xem còn thấy đau như vậy huống gì người trong cuộc . thật là phẫn nộ mà . cơ quan chức năng làm việc quá chậm trễ , đến giờ mà vẫn chưa tìm ra người chịu trách nhiệm . 😠😠😠😠😠😠\n"
     ]
    }
   ],
   "source": [
    "anger_data_test_icons = anger_data['Sentence'][1]\n",
    "print(anger_data_test_icons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d6cc9c3-3be4-4925-88d9-3ff036fcace5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ko', 'phải', 'con', 'mình', ',', 'mà', 'xem', 'còn', 'thấy', 'đau', 'như', 'vậy', 'huống', 'gì', 'người', 'trong', 'cuộc', '.', 'thật', 'là', 'phẫn', 'nộ', 'mà', '.', 'cơ', 'quan', 'chức', 'năng', 'làm', 'việc', 'quá', 'chậm', 'trễ', ',', 'đến', 'giờ', 'mà', 'vẫn', 'chưa', 'tìm', 'ra', 'người', 'chịu', 'trách', 'nhiệm', '.', '😠😠😠😠😠😠']\n"
     ]
    }
   ],
   "source": [
    "#sentence2 = \"đéo được tích sự gì 😂\"\n",
    "sentence2 = anger_data['Sentence'][1]\n",
    "print(sentence2.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c3275145-87ff-4fb5-b1b6-922a1d7f54db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 'Happy' 'This is happy.']\n",
      "   0 Emotion        Sentence\n",
      "0  2   Happy  This is happy.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming anger_data_test1 is your original DataFrame\n",
    "anger_data_test1 = pd.DataFrame({\n",
    "    '0': [1, 2, 3],\n",
    "    'Emotion': ['Angry', 'Happy', 'Sad'],\n",
    "    'Sentence': ['This is angry.', 'This is happy.', 'This is sad.']\n",
    "})\n",
    "\n",
    "# Creating a new DataFrame with the row from anger_data_test1\n",
    "anger_data_test_icons1 = pd.DataFrame(columns=['0', 'Emotion', 'Sentence'])\n",
    "\n",
    "# Appending row 1 from anger_data_test1 to anger_data_test_icons1 using loc\n",
    "anger_data_test_icons1.loc[0] = anger_data_test1.loc[1].values\n",
    "\n",
    "print(anger_data_test1.loc[1].values)\n",
    "\n",
    "print(anger_data_test_icons1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f838ca8d-4a54-4dc7-9a25-680348a7ecbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "replcae_icon = {\n",
    "'😀': ':grinning_face: ’\n",
    "'😃': ':grinning_face_with_big_eyes: ’\n",
    "'😄': ':grinning_face_with_smiling_eyes: ’\n",
    "'😁': ':beaming_face_with_smiling_eyes: ’\n",
    "'😆': ':grinning_squinting_face: ’\n",
    "'😅': ':grinning_face_with_sweat: ’\n",
    "'🤣': ':rolling_on_the_floor_laughing: ’\n",
    "'😂': ':face_with_tears_of_joy: ’\n",
    "'🙂': ':slightly_smiling_face: ’\n",
    "'😉': ':winking_face: ’\n",
    "'😊': ':smiling_face_with_smiling_eyes: ’\n",
    "'😇': ':smiling_face_with_halo: ’\n",
    "'🥰': ':smiling_face_with_three_hearts: ’\n",
    "'😍': ':smiling_face_with_heart_eyes: ’\n",
    "'🤩': ':star_struck: ’\n",
    "'😘': ':face_blowing_a_kiss: ’\n",
    "'😗': ':kissing_face: ’\n",
    "'😚': ':kissing_face_with_closed_eyes: ’\n",
    "'😙': ':kissing_face_with_smiling_eyes: ’\n",
    "'😏': ':smirking_face: ’\n",
    "'😋': ':face_savoring_food: ’\n",
    "'😛': ':face_with_tongue: ’\n",
    "'😜': ':winking_face_with_tongue: ’\n",
    "'🤪': ':zany_face: ’\n",
    "'😝': ':squinting_face_with_tongue: ’\n",
    "'🤗': ':hugging_face: ’ \n",
    "'🤭': ':face_with_hand_over_mouth: ’\n",
    "'🤫': ':shushing_face: ’\n",
    "'🤔': ':thinking_face: ’\n",
    "'🤤': ':drooling_face: ’\n",
    "'🥳': ':partying_face: ’\n",
    "'😎': ':smiling_face_with_sunglasses: ’\n",
    "'🤓': ':nerd_face: ’\n",
    "'😐': ':neutral_face: ’\n",
    "'😑': ':expressionless_face: ’\n",
    "'😶': ':face_without_mouth: ’\n",
    "'😒': ':unamused_face: ’\n",
    "'🙄': ':face_with_rolling_eyes: ’\n",
    "'😬': ':grimacing_face: ’\n",
    "'😮‍💨': ':face_exhaling: ’\n",
    "'🤥': ':lying_face: ’\n",
    "'😌': ':relieved_face: ’\n",
    "'😔': ':pensive_face: ’\n",
    "'😪': ':sleepy_face: ’\n",
    "'😴': ':sleeping_face: ’\n",
    "'😷': ':face_with_medical_mask: ’\n",
    "'🤒': ':face_with_thermometer: ’\n",
    "'🤕': ':face_with_head_bandage: ’\n",
    "'🤢': ':nauseated_face: ’\n",
    "'🤮': ':face_vomiting: ’\n",
    "'🤧': ':sneezing_face: ’\n",
    "'🥵': ':hot_face: ’\n",
    "'🥶': ':cold_face: ’\n",
    "'😵': ':dizzy_face: ’\n",
    "'😵‍💫': ':face_with_spiral_eyes: ’\n",
    "'🤯': ':exploding_head: ’\n",
    "'🥱': ':yawning_face: ’\n",
    "'😕': ':confused_face: ’\n",
    "'😟': ':worried_face: ’\n",
    "'🙁': ':slightly_frowning_face: ’\n",
    "'☹️': ':frowning_face: ’\n",
    "'😮': ':face_with_open_mouth: ’\n",
    "'😯': ':hushed_face: ’\n",
    "'😲': ':astonished_face: ’\n",
    "'😳': ':flushed_face: ’\n",
    "'🥺': ':pleading_face: ’\n",
    "'😦': ':frowning_face_with_open_mouth: ’\n",
    "'😧': ':anguished_face: ’\n",
    "'😨': ':fearful_face: ’\n",
    "'😰': ':anxious_face_with_sweat: ’\n",
    "'😥': ':sad_but_relieved_face: ’\n",
    "'😢': ':crying_face: ’\n",
    "'😭': ':loudly_crying_face: ’\n",
    "'😱': ':face_screaming_in_fear: ’\n",
    "'😖': ':confounded_face: ’\n",
    "'😣': ':persevering_face: ’\n",
    "'😞': ':disappointed_face: ’\n",
    "'😓': ':downcast_face_with_sweat: ’\n",
    "'😩': ':weary_face: ’\n",
    "'😫': ':tired_face: ’\n",
    "'😤': ':face_with_steam_from_nose: ’\n",
    "'😡': ':pouting_face: ’\n",
    "'😠': ':angry_face: ’\n",
    "'🤬': ':face_with_symbols_on_mouth: ’\n",
    "'👿': ':angry_face_with_horns: ’\n",
    "'😈': ':smiling_face_with_horns: ’\n",
    "'💀': ':skull: ’\n",
    "'☠️': ':skull_and_crossbones: ’\n",
    "'💩': ':pile_of_poo: ’\n",
    "'🤡': ':clown_face: ’ \n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
